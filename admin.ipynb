{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical RAG System - Admin Panel\n",
    "\n",
    "## üîß Administrative Interface\n",
    "\n",
    "Use this interface to manage the medical knowledge base, rebuild indexes, and perform system maintenance.\n",
    "\n",
    "**‚ö†Ô∏è Access Control**: This panel should only be accessible to administrators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System initialization\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from rag import config\n",
    "from rag.cache import save_chunks, save_faiss_index, save_metadata, load_chunks, load_faiss_index\n",
    "\n",
    "print(\"‚úÖ Admin panel initialized\")\n",
    "print(f\"üìÅ Data directory: {config.DATA_DIR}\")\n",
    "print(f\"üì¶ Cache directory: {config.CACHE_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä System Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Status display\n",
    "status_output = widgets.Output()\n",
    "\n",
    "def refresh_status(button=None):\n",
    "    with status_output:\n",
    "        clear_output()\n",
    "        \n",
    "        # Check for existing data\n",
    "        chunks = load_chunks()\n",
    "        index = load_faiss_index()\n",
    "        \n",
    "        # Count PDFs\n",
    "        pdf_count = len(list(config.PDF_DIR.glob('*.pdf')))\n",
    "        \n",
    "        # Check cache files\n",
    "        cache_files = {\n",
    "            'chunks.pkl': (config.CACHE_DIR / 'chunks.pkl').exists(),\n",
    "            'faiss_index.bin': (config.CACHE_DIR / 'faiss_index.bin').exists(),\n",
    "            'metadata.json': (config.CACHE_DIR / 'chunk_metadata.json').exists()\n",
    "        }\n",
    "        \n",
    "        # Build status HTML\n",
    "        status_html = '<div style=\"background-color: #f0f9ff; padding: 20px; border-radius: 10px; border-left: 5px solid #0066cc;\">'\n",
    "        status_html += '<h3 style=\"margin-top: 0; color: #0066cc;\">üìä System Status</h3>'\n",
    "        status_html += f'<p><strong>PDF Documents:</strong> {pdf_count}</p>'\n",
    "        status_html += f'<p><strong>Processed Chunks:</strong> {len(chunks) if chunks else 0}</p>'\n",
    "        status_html += f'<p><strong>FAISS Index:</strong> {\"‚úÖ Built\" if index else \"‚ùå Not found\"}</p>'\n",
    "        status_html += '<p><strong>Cache Files:</strong></p><ul>'\n",
    "        for file, exists in cache_files.items():\n",
    "            icon = '‚úÖ' if exists else '‚ùå'\n",
    "            status_html += f'<li>{icon} {file}</li>'\n",
    "        status_html += '</ul>'\n",
    "        \n",
    "        if chunks:\n",
    "            status_html += f'<p style=\"color: #28a745; font-weight: bold; margin-top: 15px;\">System is operational and ready to serve queries.</p>'\n",
    "        else:\n",
    "            status_html += f'<p style=\"color: #dc3545; font-weight: bold; margin-top: 15px;\">System needs initialization. Please process documents below.</p>'\n",
    "        \n",
    "        status_html += '</div>'\n",
    "        display(HTML(status_html))\n",
    "\n",
    "refresh_button = widgets.Button(\n",
    "    description='üîÑ Refresh Status',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='200px', margin='10px 0')\n",
    ")\n",
    "refresh_button.on_click(refresh_status)\n",
    "\n",
    "display(refresh_button)\n",
    "display(status_output)\n",
    "refresh_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìÑ Document Management\n",
    "\n",
    "Upload PDF documents to the system for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# File upload interface\nupload_output = widgets.Output()\n\nfile_upload = widgets.FileUpload(\n    accept='.pdf',\n    multiple=True,\n    description='Upload PDFs'\n)\n\ndef handle_upload(change):\n    with upload_output:\n        clear_output()\n        uploaded_files = change['new']\n        \n        if not uploaded_files:\n            return\n        \n        display(HTML(f'<p>üì§ Uploading {len(uploaded_files)} file(s)...</p>'))\n        \n        for file_info in uploaded_files:\n            filename = file_info['name']\n            content = file_info['content']\n            filepath = config.PDF_DIR / filename\n            \n            with open(filepath, 'wb') as f:\n                f.write(content)\n            \n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Uploaded: {filename}</p>'))\n        \n        display(HTML('<p style=\"font-weight: bold; margin-top: 15px;\">Upload complete! Now run \"Process Documents\" below.</p>'))\n        refresh_status()\n\nfile_upload.observe(handle_upload, names='value')\n\ndisplay(file_upload)\ndisplay(upload_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Processing Pipeline\n",
    "\n",
    "Process documents through the complete RAG pipeline: extraction ‚Üí chunking ‚Üí header generation ‚Üí embedding ‚Üí indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Processing controls\nprocess_output = widgets.Output()\n\nprocess_button = widgets.Button(\n    description='üöÄ Process Documents',\n    button_style='success',\n    icon='cogs',\n    layout=widgets.Layout(width='200px', height='45px', margin='10px 0')\n)\n\nrebuild_button = widgets.Button(\n    description='üî® Rebuild Index',\n    button_style='warning',\n    icon='refresh',\n    layout=widgets.Layout(width='200px', height='45px', margin='10px 0')\n)\n\ndef process_documents(button):\n    with process_output:\n        clear_output(wait=True)\n        \n        display(HTML('<h3>üîÑ Starting Document Processing Pipeline...</h3>'))\n        \n        try:\n            # Step 1: Load documents from both JSON and PDFs\n            display(HTML('<p>üìÑ Step 1/6: Loading documents from JSON and PDFs...</p>'))\n            from rag.ingestion import extract_text_from_pdfs, load_json_documents\n            \n            # Load JSON documents (web-scraped)\n            json_docs = load_json_documents(config.DATA_DIR)\n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Loaded {len(json_docs)} JSON documents</p>'))\n            \n            # Extract PDF documents\n            pdf_docs = extract_text_from_pdfs(config.PDF_DIR)\n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Extracted {len(pdf_docs)} PDF documents</p>'))\n            \n            # Combine all documents\n            documents = json_docs + pdf_docs\n            display(HTML(f'<p style=\"color: #0066cc; font-weight: bold;\">üìö Total: {len(documents)} documents</p>'))\n            \n            # Step 2: Chunk documents\n            display(HTML('<p>‚úÇÔ∏è Step 2/6: Chunking documents with semantic boundaries...</p>'))\n            from rag.chunking import SemanticChunker\n            chunker = SemanticChunker(max_words=config.SEMANTIC_MAX_WORDS)\n            chunks = chunker.chunk_documents(documents)\n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Created {len(chunks)} chunks</p>'))\n            \n            # Step 3: Generate contextual headers\n            display(HTML('<p>üè∑Ô∏è Step 3/6: Generating contextual headers...</p>'))\n            from rag.headers import ContextualHeaderGenerator\n            header_gen = ContextualHeaderGenerator()\n            chunks = header_gen.generate_headers_batch(chunks, batch_size=config.BATCH_SIZE)\n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated headers for all chunks</p>'))\n            \n            # Step 4: Generate embeddings with batching\n            display(HTML('<p>üßÆ Step 4/6: Generating embeddings...</p>'))\n            from rag.embeddings import get_embeddings_batch\n            from rag.cache import save_embeddings\n            import time\n            \n            texts_to_embed = [f\"{chunk.ctx_header}\\n\\n{chunk.raw_chunk}\" for chunk in chunks]\n            embeddings = []\n            batch_size = config.EMBED_BATCH_SIZE\n            total_batches = (len(texts_to_embed) + batch_size - 1) // batch_size\n            \n            for i in range(0, len(texts_to_embed), batch_size):\n                batch = texts_to_embed[i:i + batch_size]\n                batch_embeddings = get_embeddings_batch(batch)\n                \n                # Check for zero vectors (failed embeddings)\n                if batch_embeddings and any(sum(emb) == 0 for emb in batch_embeddings):\n                    raise RuntimeError(f\"Embedding generation failed for batch {i//batch_size + 1} (returned zero vectors)\")\n                \n                embeddings.extend(batch_embeddings)\n                batch_num = i // batch_size + 1\n                display(HTML(f'<p>üìä Completed batch {batch_num}/{total_batches}</p>'))\n                \n                # Delay between batches (except last)\n                if batch_num < total_batches:\n                    time.sleep(config.EMBED_DELAY_SECONDS)\n            \n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {len(embeddings)} embeddings</p>'))\n            \n            # Step 5: Build FAISS index\n            display(HTML('<p>üîç Step 5/6: Building FAISS search index...</p>'))\n            import numpy as np\n            import faiss\n            embeddings_array = np.array(embeddings).astype('float32')\n            dimension = embeddings_array.shape[1]\n            index = faiss.IndexFlatIP(dimension)  # Inner product for cosine similarity\n            faiss.normalize_L2(embeddings_array)  # Normalize for cosine similarity\n            index.add(embeddings_array)\n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Built FAISS index with {index.ntotal} vectors</p>'))\n            \n            # Step 6: Save everything to cache\n            display(HTML('<p>üíæ Step 6/6: Saving to cache...</p>'))\n            save_chunks(chunks)\n            save_faiss_index(index)\n            \n            # Build metadata for retrieval\n            chunk_records = []\n            for i, chunk in enumerate(chunks):\n                chunk_records.append({\n                    'chunk_id': chunk.chunk_id,\n                    'doc_title': chunk.doc_title,\n                    'source_url': chunk.source_url,\n                    'ctx_header': chunk.ctx_header,\n                    'chunk_index': chunk.chunk_index\n                })\n            save_metadata(chunk_records)\n            \n            display(HTML('<p style=\"color: #28a745;\">‚úÖ Saved to cache</p>'))\n            \n            # Success message\n            display(HTML(f'''\n                <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                    <h3 style=\"margin-top: 0;\">üéâ Processing Complete!</h3>\n                    <ul style=\"margin-bottom: 0;\">\n                        <li>JSON documents: {len(json_docs)}</li>\n                        <li>PDF documents: {len(pdf_docs)}</li>\n                        <li>Total documents processed: {len(documents)}</li>\n                        <li>Chunks created: {len(chunks)}</li>\n                        <li>Embeddings generated: {len(embeddings)}</li>\n                        <li>Index built: {index.ntotal} vectors</li>\n                    </ul>\n                    <p style=\"margin-top: 15px; margin-bottom: 0; font-weight: bold;\">The system is now ready to serve queries!</p>\n                </div>\n            '''))\n            \n            refresh_status()\n            \n        except Exception as e:\n            display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n            import traceback\n            display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n\ndef rebuild_index(button):\n    with process_output:\n        clear_output(wait=True)\n        \n        display(HTML('<h3>üî® Rebuilding FAISS Index...</h3>'))\n        \n        try:\n            # Load existing chunks\n            chunks = load_chunks()\n            if not chunks:\n                display(HTML('<p style=\"color: #dc3545;\">‚ùå No chunks found. Please process documents first.</p>'))\n                return\n            \n            display(HTML(f'<p>üì¶ Loaded {len(chunks)} existing chunks</p>'))\n            \n            # Regenerate embeddings with batching\n            display(HTML('<p>üßÆ Regenerating embeddings...</p>'))\n            from rag.embeddings import get_embeddings_batch\n            from rag.cache import save_embeddings\n            import time\n            \n            texts_to_embed = [f\"{chunk.ctx_header}\\n\\n{chunk.raw_chunk}\" for chunk in chunks]\n            embeddings = []\n            batch_size = config.EMBED_BATCH_SIZE\n            total_batches = (len(texts_to_embed) + batch_size - 1) // batch_size\n            \n            for i in range(0, len(texts_to_embed), batch_size):\n                batch = texts_to_embed[i:i + batch_size]\n                batch_embeddings = get_embeddings_batch(batch)\n                \n                # Check for zero vectors (failed embeddings)\n                if batch_embeddings and any(sum(emb) == 0 for emb in batch_embeddings):\n                    raise RuntimeError(f\"Embedding generation failed for batch {i//batch_size + 1} (returned zero vectors)\")\n                \n                embeddings.extend(batch_embeddings)\n                batch_num = i // batch_size + 1\n                display(HTML(f'<p>üìä Completed batch {batch_num}/{total_batches}</p>'))\n                \n                # Delay between batches (except last)\n                if batch_num < total_batches:\n                    time.sleep(config.EMBED_DELAY_SECONDS)\n            \n            display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Generated {len(embeddings)} embeddings</p>'))\n            \n            # Rebuild index\n            display(HTML('<p>üîç Building new FAISS index...</p>'))\n            import numpy as np\n            import faiss\n            embeddings_array = np.array(embeddings).astype('float32')\n            dimension = embeddings_array.shape[1]\n            index = faiss.IndexFlatIP(dimension)\n            faiss.normalize_L2(embeddings_array)\n            index.add(embeddings_array)\n            \n            # Save\n            save_faiss_index(index)\n            \n            display(HTML(f'''\n                <div style=\"background-color: #d4edda; border: 1px solid #c3e6cb; color: #155724; padding: 20px; border-radius: 10px; margin-top: 20px;\">\n                    <h3 style=\"margin-top: 0;\">‚úÖ Index Rebuilt Successfully!</h3>\n                    <p style=\"margin-bottom: 0;\">FAISS index updated with {index.ntotal} vectors.</p>\n                </div>\n            '''))\n            \n            refresh_status()\n            \n        except Exception as e:\n            display(HTML(f'<p style=\"color: #dc3545; font-weight: bold;\">‚ùå Error: {str(e)}</p>'))\n            import traceback\n            display(HTML(f'<pre style=\"background-color: #f8f9fa; padding: 10px; border-radius: 5px; font-size: 11px;\">{traceback.format_exc()}</pre>'))\n\nprocess_button.on_click(process_documents)\nrebuild_button.on_click(rebuild_index)\n\ndisplay(widgets.HBox([process_button, rebuild_button]))\ndisplay(process_output)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üóëÔ∏è Cache Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache management\n",
    "cache_output = widgets.Output()\n",
    "\n",
    "clear_cache_button = widgets.Button(\n",
    "    description='üóëÔ∏è Clear Cache',\n",
    "    button_style='danger',\n",
    "    layout=widgets.Layout(width='200px', margin='10px 0')\n",
    ")\n",
    "\n",
    "def clear_cache(button):\n",
    "    with cache_output:\n",
    "        clear_output()\n",
    "        \n",
    "        display(HTML('<p>‚ö†Ô∏è Clearing cache files...</p>'))\n",
    "        \n",
    "        cache_files = [\n",
    "            config.CACHE_DIR / 'chunks.pkl',\n",
    "            config.CACHE_DIR / 'faiss_index.bin',\n",
    "            config.CACHE_DIR / 'chunk_metadata.json'\n",
    "        ]\n",
    "        \n",
    "        for filepath in cache_files:\n",
    "            if filepath.exists():\n",
    "                filepath.unlink()\n",
    "                display(HTML(f'<p style=\"color: #28a745;\">‚úÖ Deleted: {filepath.name}</p>'))\n",
    "        \n",
    "        display(HTML('<p style=\"font-weight: bold; margin-top: 15px;\">Cache cleared. Run \"Process Documents\" to rebuild.</p>'))\n",
    "        refresh_status()\n",
    "\n",
    "clear_cache_button.on_click(clear_cache)\n",
    "\n",
    "display(clear_cache_button)\n",
    "display(cache_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìà System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display system configuration\n",
    "info_html = f'''\n",
    "<div style=\"background-color: #f8f9fa; padding: 20px; border-radius: 10px; border: 1px solid #dee2e6;\">\n",
    "    <h3 style=\"margin-top: 0; color: #495057;\">‚öôÔ∏è Configuration</h3>\n",
    "    <table style=\"width: 100%; border-collapse: collapse;\">\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Data Directory:</td>\n",
    "            <td style=\"padding: 8px;\"><code>{config.DATA_DIR}</code></td>\n",
    "        </tr>\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">PDF Directory:</td>\n",
    "            <td style=\"padding: 8px;\"><code>{config.PDF_DIR}</code></td>\n",
    "        </tr>\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Cache Directory:</td>\n",
    "            <td style=\"padding: 8px;\"><code>{config.CACHE_DIR}</code></td>\n",
    "        </tr>\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Embedding Model:</td>\n",
    "            <td style=\"padding: 8px;\"><code>{config.AOAI_EMBED_MODEL}</code></td>\n",
    "        </tr>\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Chat Model:</td>\n",
    "            <td style=\"padding: 8px;\"><code>{config.AOAI_CHAT_MODEL}</code></td>\n",
    "        </tr>\n",
    "        <tr style=\"border-bottom: 1px solid #dee2e6;\">\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Max Chunk Words:</td>\n",
    "            <td style=\"padding: 8px;\">{config.SEMANTIC_MAX_WORDS}</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 8px; font-weight: bold;\">Embedding Batch Size:</td>\n",
    "            <td style=\"padding: 8px;\">{config.EMBED_BATCH_SIZE}</td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "'''\n",
    "\n",
    "display(HTML(info_html))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}